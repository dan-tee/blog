{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to learn an algorithm is to watch it in action. That is why I created the simplest non linear neural network in [Keras](http://keras.io) and trained it on the simplest non linear example. I learned way more on this that I expected. That is why I created some awesome visualization of how this simple network learns. I hope this helps people who want to get started with neural nets.\n",
    "\n",
    "The data that we are going to predict is generated by a bilinear function that is `0` in the interval `[0, 1]` and has the value `x-1` on the interval `[1, 2]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAACpCAYAAAB9AmW8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZFEDFAiIokYoEREEjFAiYgk+j/Mh/U3Hts0RAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10961c4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "n_points = 100\n",
    "x = np.linspace(0, 2, n_points)\n",
    "y = np.array([0] * int(n_points/2) + list(x[:50]))\n",
    "plt.figure(figsize=(5, 2))\n",
    "plt.plot(x, y, linewidth=2)\n",
    "plt.title('the data')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural network magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import Callback\n",
    "model = Sequential()\n",
    "\n",
    "n_conn = 1\n",
    "model.add(Dense(output_dim=n_conn, input_dim=1, init=\"glorot_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "#model.add(Dense(output_dim=1, init=\"glorot_normal\"))\n",
    "\n",
    "# from keras.optimizers import RMSprop\n",
    "# opti = RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)\n",
    "# model.compile(loss='mean_squared_error', optimizer=opti)\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "X_train = np.array(x, ndmin=2).T\n",
    "Y_train = np.array(y, ndmin=2).T\n",
    "\n",
    "%matplotlib notebook\n",
    "epochs = 10000\n",
    "batch_size = 100\n",
    "n_batches = n_points / batch_size\n",
    "\n",
    "class PlotLoss(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "        self.fig = fig\n",
    "        self.ax1 = ax1\n",
    "        ax1.set_xlim([0, n_batches * epochs])\n",
    "        #ax1.set_ylim([0, 1])\n",
    "        self.ax2 = ax2\n",
    "        \n",
    "        self.losses = []\n",
    "        self.i = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.i += 1\n",
    "        if self.i % 500 == 0:        \n",
    "            if len(self.ax1.lines):\n",
    "                self.ax1.lines[0].set_xdata(range(len(self.losses)))\n",
    "                self.ax1.lines[0].set_ydata(self.losses)\n",
    "            else:\n",
    "                self.ax1.plot(self.losses)\n",
    "                self.ax1.set_title('training loss')\n",
    "            self.fig.canvas.draw()\n",
    "        \n",
    "        if self.i % 500 == 0:        \n",
    "            pred = model.predict(X_train)\n",
    "            if len(self.ax2.lines):\n",
    "                self.ax2.lines[0].set_xdata(x)\n",
    "                self.ax2.lines[0].set_ydata(y)\n",
    "                self.ax2.lines[1].set_xdata(x)\n",
    "                self.ax2.lines[1].set_ydata(pred)\n",
    "            else:\n",
    "                self.ax2.plot(x, pred, label='prediction')\n",
    "                self.ax2.plot(x, y, label='data')\n",
    "                self.ax2.legend(loc='upper left')\n",
    "            self.fig.canvas.draw()\n",
    "            \n",
    "loss = PlotLoss()\n",
    "%time model.fit(X_train,\n",
    "                Y_train,\n",
    "                nb_epoch=epochs,\n",
    "                batch_size=batch_size,\n",
    "                verbose=0,\n",
    "                callbacks=[loss])\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_train)\n",
    "plt.plot(x, pred)\n",
    "plt.plot(x, y)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def get_layer_outoput(layer):\n",
    "    return K.function([model.layers[0].input],\n",
    "                      [model.layers[layer].get_output(train=False)])\n",
    "\n",
    "print('weigths')\n",
    "print(model.layers[0].get_weights())\n",
    "#print(model.layers[2].get_weights())\n",
    "print()\n",
    "\n",
    "print('layers for input 0')\n",
    "print(get_layer_outoput(0)([X_train[0:1,:]])[0])\n",
    "print(get_layer_outoput(1)([X_train[0:1,:]])[0])\n",
    "#print(get_layer_outoput(2)([X_train[0:1,:]])[0])\n",
    "print()\n",
    "\n",
    "print('layers for input 0.5')\n",
    "print(get_layer_outoput(0)([X_train[5:6,:]])[0])\n",
    "print(get_layer_outoput(1)([X_train[5:6,:]])[0])\n",
    "#print(get_layer_outoput(2)([X_train[5:6,:]])[0])\n",
    "print()\n",
    "\n",
    "print('layers for input 1')\n",
    "print(get_layer_outoput(0)([X_train[10:11,:]])[0])\n",
    "print(get_layer_outoput(1)([X_train[10:11,:]])[0])\n",
    "#print(get_layer_outoput(2)([X_train[10:11,:]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
